{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY2QPYpcnFcc"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVZ5GYSHtfsM",
        "outputId": "5d0d07e3-5408-4f02-d6d8-29b485f33c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nojq_9wnFcd"
      },
      "source": [
        "Обработка естественного языка с нуля: перевод с помощью сети последовательностей и внимания\n",
        "===============================================================================\n",
        "\n",
        "\n",
        "В этом проекте мы будем обучать нейронную сеть переводить с русского на английский.\n",
        "\n",
        "\\... в разной степени успешности.\n",
        "\n",
        "Это становится возможным благодаря простой, но мощной идее [сети последовательности к последовательности](https://arxiv.org/abs/1409.3215), в которой две рекуррентные нейронные сети работают вместе, чтобы преобразовать одну последовательность в другую. Сеть энкодера сжимает входную последовательность в вектор, а сеть декодера разворачивает этот вектор в новую последовательность.\n",
        "\n",
        "![](https://pytorch.org/tutorials/_static/img/seq-seq-images/seq2seq.png)\n",
        "\n",
        "Чтобы улучшить эту модель, мы будем использовать [механизм внимания](https://arxiv.org/abs/1409.0473), который позволяет декодеру научиться фокусироваться на определенном диапазоне входной последовательности.\n",
        "\n",
        "**Требования**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tUmABlinFce"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jo6hWAGnFce"
      },
      "source": [
        "Загрузка файлов данных\n",
        "==================\n",
        "\n",
        "Для этого проекта данные представляют собой набор множеств тысяч пар английских и русских переводов.\n",
        "\n",
        "Пары английский-французский слишком большие, чтобы включить их в репозиторий, поэтому загрузите их в `data/rus-eng.txt`, прежде чем продолжить. Файл представляет собой список пар переводов, разделенных табуляцией:\n",
        "\n",
        "``` {.sourceCode .sh}\n",
        "Wow!\tЗдорово!\n",
        "```\n",
        "\n",
        "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>ПРИМЕЧАНИЕ:</strong></div>\n",
        "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
        "<p>Загрузите данные с <a href=\"https://www.manythings.org/anki/rus-eng.zip\">этого</a> сайта и извлеките их в текущий каталог.</p>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn5uQA9TnFce"
      },
      "source": [
        "Similar to the character encoding used in the character-level RNN\n",
        "tutorials, we will be representing each word in a language as a one-hot\n",
        "vector, or giant vector of zeros except for a single one (at the index\n",
        "of the word). Compared to the dozens of characters that might exist in a\n",
        "language, there are many many more words, so the encoding vector is much\n",
        "larger. We will however cheat a bit and trim the data to only use a few\n",
        "thousand words per language.\n",
        "\n",
        "![](https://pytorch.org/tutorials/_static/img/seq-seq-images/word-encoding.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2Xj3zudnFce"
      },
      "source": [
        "Нам понадобится уникальный индекс для каждого слова, чтобы использовать его в качестве входных и целевых данных для сетей позже. Чтобы отслеживать все это, мы будем использовать вспомогательный класс под названием `Lang`, который содержит словари слово → индекс (`word2index`) и индекс → слово (`index2word`), а также подсчет каждого слова `word2count`, который будет использоваться позже для замены редких слов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euOWFt-9nFce"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FocuCtrOnFcf"
      },
      "source": [
        "Все файлы находятся в формате Unicode. Для упрощения мы преобразуем символы Unicode в ASCII, приведем все к нижнему регистру и удалим большую часть знаков пунктуации.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5Z7cu5pnFcf"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^а-яА-Яa-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9K_fuChnFcf"
      },
      "source": [
        "Чтобы прочитать файл данных, мы разобьем файл на строки, а затем разобьем строки на пары. Все файлы имеют формат Английский → Другой язык, поэтому если мы хотим перевести с Другого языка → Английский, я добавил флаг `reverse`, чтобы перевернуть пары.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwDTslecnFcf"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sQSjz16nFcf"
      },
      "source": [
        "Поскольку у нас очень *много* примеров предложений, и мы хотим быстро обучить что-то, мы сократим набор данных до относительно коротких и простых предложений. Максимальная длина здесь составляет 10 слов (включая конечную пунктуацию), и мы фильтруем предложения так, чтобы они переводились в форму \"Я\" или \"Он\" и т.д. (учитывая апострофы, замененные ранее).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0aetTA_nFcf"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HSB9JU_nFcf"
      },
      "source": [
        "Полный процесс подготовки данных включает в себя следующее:\n",
        "\n",
        "- Чтение текстового файла и разбиение на строки, разбиение строк на пары\n",
        "- Нормализация текста, фильтрация по длине и содержанию\n",
        "- Создание списков слов из предложений в парах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G530-TrUnFcf",
        "outputId": "cb61dd23-8566-41aa-8fb8-1c17a1073cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 487600 sentence pairs\n",
            "Trimmed to 30189 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 10444\n",
            "rus 4333\n",
            "['ты выше отца', 'you re taller than your father']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('rus', 'eng', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHSG0idjnFcf"
      },
      "source": [
        "Модель Seq2Seq\n",
        "=================\n",
        "\n",
        "Рекуррентная нейронная сеть, или RNN, - это сеть, которая оперирует над последовательностью и использует свой собственный вывод в качестве входа для последующих шагов.\n",
        "\n",
        "Сеть [Последовательность к Последовательности](https://arxiv.org/abs/1409.3215), или seq2seq, или [Сеть Энкодер-Декодер](https://arxiv.org/pdf/1406.1078v3.pdf), - это модель, состоящая из двух RNN, называемых энкодером и декодером. Энкодер считывает входную последовательность и выводит один вектор, а декодер читает этот вектор, чтобы произвести выходную последовательность.\n",
        "\n",
        "![](https://pytorch.org/tutorials/_static/img/seq-seq-images/seq2seq.png)\n",
        "\n",
        "В отличие от прогнозирования последовательности с помощью одной RNN, где каждый вход соответствует выходу, модель seq2seq освобождает нас от длины и порядка последовательности, что делает ее идеальной для перевода между двумя языками.\n",
        "\n",
        "Рассмотрим предложение `Je ne suis pas le chat noir` → `I am not the black cat`. Большинство слов во входном предложении имеют прямой перевод в выходном предложении, но они немного отличаются по порядку, например, `chat noir` и `black cat`. Из-за конструкции `ne/pas` во входном предложении также есть еще одно слово. Было бы сложно непосредственно из последовательности входных слов получить правильный перевод.\n",
        "\n",
        "С помощью модели seq2seq энкодер создает один вектор, который, в идеальном случае, кодирует \"смысл\" входной последовательности в один вектор - одну точку в некотором N-мерном пространстве предложений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6J8aSf45nFcg"
      },
      "source": [
        "Энкодер\n",
        "===========\n",
        "\n",
        "Энкодер сети seq2seq - это рекуррентная нейронная сеть (RNN), которая выдает некоторое значение для каждого слова из входного предложения. Для каждого входного слова энкодер выдает вектор и скрытое состояние, и использует скрытое состояние для следующего входного слова.\n",
        "\n",
        "![](https://pytorch.org/tutorials/_static/img/seq-seq-images/encoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDLWugainFcg"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z-21tbTnFcg"
      },
      "source": [
        "Декодер\n",
        "===========\n",
        "\n",
        "Декодер - это еще одна рекуррентная нейронная сеть (RNN), которая принимает вектор(ы) выхода энкодера и выдает последовательность слов для создания перевода."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4EMVUiKnFcg"
      },
      "source": [
        "Простой декодер\n",
        "==============\n",
        "\n",
        "В самом простом декодере seq2seq мы используем только последний выход энкодера. Этот последний выход иногда называется *вектором контекста*, так как он кодирует контекст из всей последовательности. Этот вектор контекста используется в качестве начального скрытого состояния декодера.\n",
        "\n",
        "На каждом шаге декодирования декодеру передается токен ввода и скрытое состояние. Начальный входной токен - это токен начала строки `<SOS>`, а первое скрытое состояние - это вектор контекста (последнее скрытое состояние энкодера).\n",
        "\n",
        "![](https://pytorch.org/tutorials/_static/img/seq-seq-images/decoder-network.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXK5l2fpnFcg"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
        "\n",
        "    def forward_step(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.out(output)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3xFIHa1nFcg"
      },
      "source": [
        "# Декодер внимания\n",
        "\n",
        "Если между энкодером и декодером передается только вектор контекста, то этот единственный вектор несет на себе бремя кодирования всего предложения.\n",
        "\n",
        "Механизм внимания позволяет сети декодера \"фокусироваться\" на разных частях выходов энкодера для каждого шага собственных выходов декодера. Сначала мы вычисляем набор *весов внимания*. Они будут умножены на векторы выхода энкодера для создания взвешенной комбинации. Результат (называемый `attn_applied` в коде) должен содержать информацию о конкретной части входной последовательности и таким образом помогать декодеру выбирать правильные выходные слова.\n",
        "\n",
        "![](https://i.imgur.com/1152PYf.png)\n",
        "\n",
        "Вычисление весов внимания выполняется с помощью еще одного слоя прямого распространения `attn`, используя вход декодера и скрытое состояние в качестве входных данных. Поскольку в обучающих данных есть предложения всех размеров, чтобы фактически создать и обучить этот слой, нам нужно выбрать максимальную длину предложения (длину ввода для выходов энкодера), которую он может применять. Предложения максимальной длины будут использовать все веса внимания, в то время как более короткие предложения будут использовать только первые несколько.\n",
        "\n",
        "![](https://pytorch.org/tutorials/_static/img/seq-seq-images/attention-decoder-network.png)\n",
        "\n",
        "Механизм внимания Бахданау, также известный как аддитивное внимание, является широко используемым механизмом внимания в моделях последовательность-последовательность, особенно в задачах нейронного машинного перевода. Он был представлен Бахданау и др. в своей статье под названием [Нейронный машинный перевод совместным обучением выравнивания и перевода](https://arxiv.org/pdf/1409.0473.pdf). Этот механизм внимания использует обучаемую модель выравнивания для вычисления оценок внимания между скрытыми состояниями энкодера и декодера. Он использует нейронную сеть прямого распространения для вычисления оценок выравнивания.\n",
        "\n",
        "Однако существуют альтернативные механизмы внимания, такие как внимание Луонга, которое вычисляет оценки внимания, умножая скалярно скрытое состояние декодера на скрытые состояния энкодера. Оно не включает нелинейное преобразование, используемое в механизме внимания Бахданау."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E0fNK4dnFcg"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cmb8-LAnFcg"
      },
      "source": [
        "Обучение\n",
        "========\n",
        "\n",
        "Подготовка обучающих данных\n",
        "-----------------------\n",
        "\n",
        "Для обучения нам потребуется тензор входных данных (индексы слов во входном предложении) и целевой тензор (индексы слов в целевом предложении) для каждой пары. При создании этих векторов мы добавим токен EOS в обе последовательности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Y47zeu4nFch"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('rus', 'eng', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVX-yIWfnFch"
      },
      "source": [
        "Обучение модели\n",
        "==================\n",
        "\n",
        "Для обучения мы передаем входное предложение через энкодер и отслеживаем каждый выход и последнее скрытое состояние. Затем декодеру передается токен `<SOS>` в качестве его первого входа, а последнее скрытое состояние энкодера - в качестве его первого скрытого состояния.\n",
        "\n",
        "\"Принуждение учителя\" - это концепция использования реальных целевых выходных данных в качестве следующего входа, вместо использования догадки декодера в качестве следующего входа. Использование принуждения учителя позволяет сети быстрее сходиться, но [когда обученная сеть используется, она может проявлять нестабильность](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf).\n",
        "\n",
        "Вы можете наблюдать выводы сетей с принуждением учителя, которые читают с логичной грамматикой, но удаляются далеко от правильного перевода - интуитивно она научилась представлять грамматику выхода и может \"уловить\" значение, когда учитель говорит ей первые несколько слов, но она не научилась правильно создавать предложение из перевода с самого начала.\n",
        "\n",
        "Из-за свободы, которую дает нам автоград PyTorch, мы можем случайным образом решать, использовать ли принуждение учителя или нет с помощью простого оператора if. Увеличьте `teacher_forcing_ratio`, чтобы использовать его больше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQAjEgB7nFch"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQiZ_qNNnFch"
      },
      "source": [
        "Это вспомогательная функция для вывода затраченного времени и оценки оставшегося времени на основе текущего времени и процента выполнения.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyLwQUjenFch"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOiW8oqInFch"
      },
      "source": [
        "Весь процесс обучения выглядит следующим образом:\n",
        "\n",
        "- Запустить таймер\n",
        "- Инициализировать оптимизаторы и критерии\n",
        "- Создать набор обучающих пар\n",
        "- Начать с пустого массива потерь для построения графиков\n",
        "\n",
        "Затем мы много раз вызываем функцию `train` и время от времени выводим прогресс (% примеров, затраченное время, оцененное время) и среднюю потерю."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGGy7UP6nFch"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSsKg81nnFch"
      },
      "source": [
        "Визуализация результатов\n",
        "================\n",
        "\n",
        "Для построения графиков используется библиотека matplotlib, используя массив значений потерь `plot_losses`, сохраненных во время обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRRyMWDnnFch"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKW6Mz0RnFch"
      },
      "source": [
        "Оценка\n",
        "==========\n",
        "\n",
        "Оценка в основном аналогична обучению, но здесь нет целевых данных, поэтому мы просто подаем предсказания декодера обратно ему самому на каждом шаге. Каждый раз, когда он предсказывает слово, мы добавляем его в выходную строку, и если он предсказывает токен EOS, мы останавливаемся. Мы также сохраняем выходы внимания декодера для отображения позже."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2Ac_rATnFci"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoOA7kcEnFci"
      },
      "source": [
        "Мы можем оценить случайные предложения из обучающего набора и вывести вход, целевую и выходную информацию, чтобы сделать некоторые субъективные оценки качества:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5eCbxuDnFci"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN668x4xnFci"
      },
      "source": [
        "Обучение и оценка\n",
        "=======================\n",
        "\n",
        "Со всеми этими вспомогательными функциями (которые кажутся лишней работой, но делают запуск нескольких экспериментов более простым) мы можем фактически инициализировать сеть и начать обучение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHhLk5HnFci",
        "outputId": "1abc3cf5-59c7-4899-b19e-63ff98370afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 487600 sentence pairs\n",
            "Trimmed to 30189 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 10444\n",
            "rus 4333\n",
            "10m 17s (- 154m 15s) (5 6%) 1.2607\n",
            "20m 39s (- 144m 37s) (10 12%) 0.5007\n",
            "30m 57s (- 134m 9s) (15 18%) 0.2826\n",
            "41m 8s (- 123m 24s) (20 25%) 0.1894\n",
            "51m 20s (- 112m 57s) (25 31%) 0.1427\n",
            "61m 41s (- 102m 48s) (30 37%) 0.1167\n",
            "71m 58s (- 92m 31s) (35 43%) 0.1009\n",
            "82m 15s (- 82m 15s) (40 50%) 0.0904\n",
            "92m 24s (- 71m 52s) (45 56%) 0.0824\n",
            "102m 53s (- 61m 43s) (50 62%) 0.0776\n",
            "113m 32s (- 51m 36s) (55 68%) 0.0726\n",
            "124m 45s (- 41m 35s) (60 75%) 0.0691\n",
            "135m 26s (- 31m 15s) (65 81%) 0.0666\n",
            "145m 54s (- 20m 50s) (70 87%) 0.0645\n",
            "156m 30s (- 10m 26s) (75 93%) 0.0621\n",
            "167m 6s (- 0m 0s) (80 100%) 0.0609\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HzOLuD7nFci"
      },
      "source": [
        "Установите слои отсева в режим `eval`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rS0P88hnFci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a92e504-6287-46ef-c8bb-a4a87e2b1ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> я невероятно занят\n",
            "= i m incredibly busy\n",
            "< i am incredibly busy <EOS>\n",
            "\n",
            "> ты очень груб\n",
            "= you re being very rude\n",
            "< you re very rude <EOS>\n",
            "\n",
            "> мы с томом почти ровесники\n",
            "= i m almost as old as tom\n",
            "< i expected almost about tom <EOS>\n",
            "\n",
            "> я рад что мы договорились\n",
            "= i m glad we agree\n",
            "< i m glad we agree <EOS>\n",
            "\n",
            "> он по праву гордится сыном\n",
            "= he is justly proud of his son\n",
            "< he is justly proud of his son <EOS>\n",
            "\n",
            "> я готова идти за вами\n",
            "= i m ready to follow you\n",
            "< i am ready to follow you <EOS>\n",
            "\n",
            "> я устал от такои жизни\n",
            "= i m tired of living this kind of life\n",
            "< i m tired of living this kind of life <EOS>\n",
            "\n",
            "> он высок но его брат намного выше\n",
            "= he is tall but his brother is much taller\n",
            "< he is tall but his brother is much taller <EOS>\n",
            "\n",
            "> я слишком устал для спора\n",
            "= i m too tired to argue\n",
            "< i m too tired to argue <EOS>\n",
            "\n",
            "> мы работаем над этим прямо сеичас\n",
            "= we re working on that right now\n",
            "< we re working on that right now <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-cXVmZYnFcj"
      },
      "source": [
        "Визуализация внимания\n",
        "=====================\n",
        "\n",
        "Полезное свойство механизма внимания - его высокая интерпретируемость. Поскольку он используется для взвешивания конкретных выходов энкодера входной последовательности, мы можем представить себе, на что сеть сфокусирована больше всего на каждом временном шаге.\n",
        "\n",
        "Для более удобного просмотра мы выполним дополнительную работу по добавлению осей и меток:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lX_oIGVnFcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87470876-9815-4671-ef9c-9277f08122b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = я невероятно занят\n",
            "output = i am incredibly busy <EOS>\n",
            "input = он по праву гордится сыном\n",
            "output = he is justly proud of his son <EOS>\n",
            "input = мы с томом почти ровесники\n",
            "output = i expected almost about tom <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-6fa1f6ab916b>:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
            "<ipython-input-27-6fa1f6ab916b>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
            "  ax.set_yticklabels([''] + output_words)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = мы работаем над этим прямо сеичас\n",
            "output = we re working on that right now <EOS>\n"
          ]
        }
      ],
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"я невероятно занят\")\n",
        "\n",
        "evaluateAndShowAttention('он по праву гордится сыном')\n",
        "\n",
        "evaluateAndShowAttention('мы с томом почти ровесники')\n",
        "\n",
        "evaluateAndShowAttention('мы работаем над этим прямо сеичас')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUysqD70nFcj"
      },
      "source": [
        "Выводы\n",
        "=========\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}